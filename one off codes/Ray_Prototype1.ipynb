{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ray_Prototype1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eg7fVgFSIb_",
        "outputId": "c18ed507-17d2-48b3-a115-aa496201953a"
      },
      "source": [
        "%cd /content\n",
        "!mkdir traning_demo\n",
        "!mkdir traning_demo/pre-trained-models\n",
        "!mkdir traning_demo/annotations\n",
        "!mkdir traning_demo/export_model"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ2YwgTSYaL9",
        "outputId": "d603d83e-7a33-43ec-9f6d-34d45b39af5d"
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/a2/5ccf0a418eb22e0a2ae9edc1e7f5456d0a4b8b49524572897564b4030a9b/tensorflow_gpu-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3MB)\n",
            "\u001b[K     |████████████████████████████████| 454.3MB 14kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.5.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.34.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.5.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.4.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.36.2)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.19.5)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.7.4.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow-gpu) (57.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (1.31.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (0.4.4)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow-gpu) (1.5.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow-gpu) (4.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow-gpu) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-gpu) (3.1.1)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bAzF7zCYhxr",
        "outputId": "7c192d59-d1ee-491d-b41a-48d6e3bd95c6"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV962FHtZI_U",
        "outputId": "651262c8-7364-4c89-d9fc-18ed303262e9"
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 57660, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 57660 (delta 36), reused 20 (delta 0), pack-reused 57602\u001b[K\n",
            "Receiving objects: 100% (57660/57660), 572.87 MiB | 31.06 MiB/s, done.\n",
            "Resolving deltas: 100% (40009/40009), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQsehCa1ZMYD",
        "outputId": "708b6591-89a1-4830-b02f-a87a72dbb135"
      },
      "source": [
        "%cd /content/models/research"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD3zPd4hZUE7"
      },
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuqyN3FdZWSb",
        "outputId": "cfb7a589-adc1-4e6a-a066-14adf6a3b712"
      },
      "source": [
        "!git clone https://github.com/cocodataset/cocoapi.git"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cocoapi'...\n",
            "remote: Enumerating objects: 975, done.\u001b[K\n",
            "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
            "Receiving objects: 100% (975/975), 11.72 MiB | 22.23 MiB/s, done.\n",
            "Resolving deltas: 100% (576/576), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSDAY2V2Zcai",
        "outputId": "8821a15c-cbd9-47d6-9595-753d433c8215"
      },
      "source": [
        "%cd cocoapi/PythonAPI"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/cocoapi/PythonAPI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeCTllcEZfgK",
        "outputId": "7123eb0d-690e-49ce-935b-e2e3a89856db"
      },
      "source": [
        "!make"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python setup.py build_ext --inplace\n",
            "running build_ext\n",
            "cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n",
            "/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/models/research/cocoapi/PythonAPI/pycocotools/_mask.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "building 'pycocotools._mask' extension\n",
            "creating build\n",
            "creating build/common\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
            "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
            "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
            "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
            "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
            "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
            "       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n",
            "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> pycocotools\n",
            "rm -rf build\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXMIRNr7Zht7"
      },
      "source": [
        "%cp -r pycocotools /content/models/research"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_CBqP2obZu4C",
        "outputId": "cca76214-c90e-4660-943c-1cee149e4724"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/research/cocoapi/PythonAPI'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9x8pSsjZw77",
        "outputId": "2c4eca2d-3b9f-4bc9-cbd6-fd416424ce34"
      },
      "source": [
        "%cd ../.."
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc-XxrHQZz_D"
      },
      "source": [
        "%cp object_detection/packages/tf2/setup.py  ."
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9m70fZghaTDC",
        "outputId": "7aed4fd0-af0e-442f-90df-6b36c841b885"
      },
      "source": [
        "!python -m pip install ."
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/models/research\n",
            "Collecting avro-python3\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/97/7a6970380ca8db9139a3cc0b0e3e0dd3e4bc584fb3644e1d06e71e1a55f0/avro-python3-1.10.2.tar.gz\n",
            "Collecting apache-beam\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/c9/395a9759dfbf9e87203a69c33b2e94f10d566d9391bddb6f99facafe64c3/apache_beam-2.30.0-cp37-cp37m-manylinux2010_x86_64.whl (9.6MB)\n",
            "\u001b[K     |████████████████████████████████| 9.6MB 10.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.23)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 31.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n",
            "Collecting lvis\n",
            "  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
            "Collecting tf-models-official\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/08/81bbc275e8e9c6d1e03dd26daec3a67f45e6322804cbce3d51f93eae1961/tf_models_official-2.5.0-py2.py3-none-any.whl (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 30.4MB/s \n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 39.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: httplib2<0.20.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.34.1)\n",
            "Requirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.4)\n",
            "Requirement already satisfied: pyarrow<4.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n",
            "Collecting fastavro<2,>=0.21.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/d1/8f5c8611026f0ddcd86a8e2f965998e0c159af980c31efba72342c69f3e4/fastavro-1.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 28.6MB/s \n",
            "\u001b[?25hCollecting future<1.0.0,>=0.18.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 26.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: numpy<1.21.0,>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n",
            "Collecting requests<3.0.0,>=2.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/08/f7/4c3fad73123a24d7394b6f40d1ec9c1cbf2e921cfea1797216ffd0a51fb1/hdfs-2.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.11.4)\n",
            "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->object-detection==0.1) (57.0.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 26.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (2.5.0)\n",
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.5MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 27.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.12.0)\n",
            "Collecting opencv-python-headless\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/35/bfc76533f2274cd3da4e2cf255cd13ab9d7f6fc8990c06911e7f8fcc2130/opencv_python_headless-4.5.2.54-cp37-cp37m-manylinux2014_x86_64.whl (38.2MB)\n",
            "\u001b[K     |████████████████████████████████| 38.2MB 72kB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.4.0)\n",
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 34.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.12.8)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/8f/f6969dc64709c5c5e22cfd7057a83adbc927e6855a431b234168222cbf03/tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl (211kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 38.5MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.5.12)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/ba/77120e44cbe9719152415b97d5bfb29f4053ee987d6cb63f55ce7d50fadc/py-cpuinfo-8.0.0.tar.gz (99kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2021.5.30)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.36.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.26.3)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.31.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official->object-detection==0.1) (0.1.6)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official->object-detection==0.1) (0.22.2.post1)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (5.1.4)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (21.2.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (4.41.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (5.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.53.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (20.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.2.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (4.5.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.1.1)\n",
            "Building wheels for collected packages: object-detection, avro-python3, dill, future, seqeval, py-cpuinfo\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-cp37-none-any.whl size=1654779 sha256=ac7dea750db7ca6530f51f686739790eca36f3ad5c31080f6122eafab61383fb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fm0s0r7e/wheels/94/49/4b/39b051683087a22ef7e80ec52152a27249d1a644ccf4e442ea\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-cp37-none-any.whl size=44011 sha256=105f047438000d4f99bbb656030793385d1e886223b7da42247280425284fe95\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/ee/18/c466221ca6900e3efce2f4ea9c329288808679aecdcb2838d3\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-cp37-none-any.whl size=78545 sha256=ee4224e0e1b52c447bd9259a5b349c51a0f3776f8c1f5fdf314a624b9f56d5e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491070 sha256=665cbc86678742d7d4ae5bb75ca40d92857701e147cbaf9ed92f84299500ac23\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16184 sha256=8e11a742f96940c9e3b383ba51c979dbcc4f13096a2fbe098b9b7bfa0b608524\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-cp37-none-any.whl size=22258 sha256=7c22eac36646bee602312eea2bff2adf20bbaa31db87a79130df7cf0afaaf57a\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/15/f5/aa2a056d223903b52cf4870134e3a01df0c723816835dd08db\n",
            "Successfully built object-detection avro-python3 dill future seqeval py-cpuinfo\n",
            "\u001b[31mERROR: multiprocess 0.70.11.1 has requirement dill>=0.3.3, but you'll have dill 0.3.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: apache-beam 2.30.0 has requirement avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you'll have avro-python3 1.10.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: avro-python3, dill, fastavro, future, requests, hdfs, apache-beam, tf-slim, lvis, sentencepiece, portalocker, sacrebleu, pyyaml, opencv-python-headless, tensorflow-addons, tensorflow-model-optimization, seqeval, py-cpuinfo, tf-models-official, object-detection\n",
            "  Found existing installation: dill 0.3.3\n",
            "    Uninstalling dill-0.3.3:\n",
            "      Successfully uninstalled dill-0.3.3\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed apache-beam-2.30.0 avro-python3-1.10.2 dill-0.3.1.1 fastavro-1.4.1 future-0.18.2 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.2.54 portalocker-2.0.0 py-cpuinfo-8.0.0 pyyaml-5.4.1 requests-2.25.1 sacrebleu-1.5.1 sentencepiece-0.1.95 seqeval-1.2.2 tensorflow-addons-0.13.0 tensorflow-model-optimization-0.6.0 tf-models-official-2.5.0 tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjAWRV1NaYN6",
        "outputId": "534e3c33-66dc-47b7-c8ba-e43ee4dfe89e"
      },
      "source": [
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-18 09:23:58.718444: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Running tests under Python 3.7.10: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2021-06-18 09:24:02.263908: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-06-18 09:24:02.338951: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-06-18 09:24:02.339037: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (d197517b1c6a): /proc/driver/nvidia/version does not exist\n",
            "2021-06-18 09:24:02.341193: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "W0618 09:24:02.651516 140498420750208 model_builder.py:1088] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.81s\n",
            "I0618 09:24:02.958175 140498420750208 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.81s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.8s\n",
            "I0618 09:24:03.760185 140498420750208 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.8s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.33s\n",
            "I0618 09:24:04.093771 140498420750208 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.33s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.3s\n",
            "I0618 09:24:04.397656 140498420750208 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.3s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "W0618 09:24:04.400644 140498420750208 mobilenet_v2.py:296] `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.61s\n",
            "I0618 09:24:07.010078 140498420750208 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.61s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0618 09:24:07.011757 140498420750208 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "I0618 09:24:07.042664 140498420750208 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I0618 09:24:07.063570 140498420750208 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I0618 09:24:07.089058 140498420750208 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.13s\n",
            "I0618 09:24:07.222683 140498420750208 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.13s\n",
            "I0618 09:24:07.351634 140498420750208 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
            "I0618 09:24:07.488934 140498420750208 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\n",
            "I0618 09:24:07.624076 140498420750208 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n",
            "I0618 09:24:07.747563 140498420750208 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "I0618 09:24:07.787446 140498420750208 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0618 09:24:08.008172 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0618 09:24:08.008462 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
            "I0618 09:24:08.008569 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n",
            "I0618 09:24:08.011531 140498420750208 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0618 09:24:08.033587 140498420750208 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0618 09:24:08.033813 140498420750208 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0618 09:24:08.121021 140498420750208 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0618 09:24:08.121254 140498420750208 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0618 09:24:08.319328 140498420750208 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0618 09:24:08.319578 140498420750208 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0618 09:24:08.517071 140498420750208 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0618 09:24:08.517357 140498420750208 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0618 09:24:08.995564 140498420750208 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0618 09:24:08.995788 140498420750208 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0618 09:24:09.322268 140498420750208 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0618 09:24:09.322502 140498420750208 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0618 09:24:09.776916 140498420750208 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0618 09:24:09.777132 140498420750208 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0618 09:24:09.903186 140498420750208 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0618 09:24:09.992562 140498420750208 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0618 09:24:10.053180 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0618 09:24:10.053421 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
            "I0618 09:24:10.053489 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 4\n",
            "I0618 09:24:10.055437 140498420750208 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0618 09:24:10.082301 140498420750208 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0618 09:24:10.082544 140498420750208 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0618 09:24:10.232324 140498420750208 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0618 09:24:10.232581 140498420750208 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0618 09:24:10.520832 140498420750208 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0618 09:24:10.521053 140498420750208 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0618 09:24:10.826912 140498420750208 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0618 09:24:10.827210 140498420750208 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0618 09:24:11.262019 140498420750208 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0618 09:24:11.262288 140498420750208 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0618 09:24:11.681078 140498420750208 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0618 09:24:11.681378 140498420750208 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0618 09:24:12.297037 140498420750208 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0618 09:24:12.297346 140498420750208 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0618 09:24:12.594381 140498420750208 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0618 09:24:12.686287 140498420750208 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0618 09:24:12.766362 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0618 09:24:12.766635 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
            "I0618 09:24:12.766702 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n",
            "I0618 09:24:12.768851 140498420750208 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0618 09:24:12.788439 140498420750208 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0618 09:24:12.788726 140498420750208 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0618 09:24:12.947291 140498420750208 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0618 09:24:12.947567 140498420750208 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0618 09:24:13.444190 140498420750208 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0618 09:24:13.444462 140498420750208 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0618 09:24:13.739873 140498420750208 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0618 09:24:13.740110 140498420750208 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0618 09:24:14.185213 140498420750208 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0618 09:24:14.185521 140498420750208 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0618 09:24:14.621491 140498420750208 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0618 09:24:14.621763 140498420750208 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0618 09:24:15.213353 140498420750208 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0618 09:24:15.213652 140498420750208 efficientnet_model.py:147] round_filter input=320 output=352\n",
            "I0618 09:24:15.525046 140498420750208 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
            "I0618 09:24:15.615873 140498420750208 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0618 09:24:15.698015 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0618 09:24:15.698299 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
            "I0618 09:24:15.698416 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 6\n",
            "I0618 09:24:15.700788 140498420750208 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0618 09:24:15.722587 140498420750208 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0618 09:24:15.722858 140498420750208 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0618 09:24:15.883798 140498420750208 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0618 09:24:15.884089 140498420750208 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0618 09:24:16.186532 140498420750208 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0618 09:24:16.186817 140498420750208 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0618 09:24:16.494573 140498420750208 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0618 09:24:16.494869 140498420750208 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0618 09:24:17.015283 140498420750208 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0618 09:24:17.015590 140498420750208 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0618 09:24:17.553027 140498420750208 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0618 09:24:17.553318 140498420750208 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0618 09:24:18.321860 140498420750208 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0618 09:24:18.322122 140498420750208 efficientnet_model.py:147] round_filter input=320 output=384\n",
            "I0618 09:24:18.844442 140498420750208 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
            "I0618 09:24:18.924733 140498420750208 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0618 09:24:19.012687 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0618 09:24:19.013001 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
            "I0618 09:24:19.013119 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0618 09:24:19.015362 140498420750208 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0618 09:24:19.037396 140498420750208 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0618 09:24:19.037702 140498420750208 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0618 09:24:19.208754 140498420750208 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0618 09:24:19.209053 140498420750208 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0618 09:24:19.622164 140498420750208 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0618 09:24:19.622478 140498420750208 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0618 09:24:20.039193 140498420750208 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0618 09:24:20.039526 140498420750208 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0618 09:24:20.700283 140498420750208 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0618 09:24:20.700591 140498420750208 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0618 09:24:21.385072 140498420750208 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0618 09:24:21.385374 140498420750208 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0618 09:24:22.481441 140498420750208 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0618 09:24:22.481712 140498420750208 efficientnet_model.py:147] round_filter input=320 output=448\n",
            "I0618 09:24:22.855087 140498420750208 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
            "I0618 09:24:22.954275 140498420750208 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0618 09:24:23.061122 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0618 09:24:23.061412 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
            "I0618 09:24:23.061513 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0618 09:24:23.068074 140498420750208 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0618 09:24:23.093051 140498420750208 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0618 09:24:23.093330 140498420750208 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0618 09:24:23.334714 140498420750208 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0618 09:24:23.335008 140498420750208 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0618 09:24:23.866309 140498420750208 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0618 09:24:23.866626 140498420750208 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0618 09:24:24.668400 140498420750208 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0618 09:24:24.668638 140498420750208 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0618 09:24:25.372637 140498420750208 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0618 09:24:25.372868 140498420750208 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0618 09:24:26.199257 140498420750208 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0618 09:24:26.199512 140498420750208 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0618 09:24:27.461022 140498420750208 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0618 09:24:27.461284 140498420750208 efficientnet_model.py:147] round_filter input=320 output=512\n",
            "I0618 09:24:28.047028 140498420750208 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
            "I0618 09:24:28.157015 140498420750208 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0618 09:24:28.277372 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0618 09:24:28.277652 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0618 09:24:28.277746 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0618 09:24:28.280125 140498420750208 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0618 09:24:28.301717 140498420750208 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0618 09:24:28.301977 140498420750208 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0618 09:24:28.539420 140498420750208 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0618 09:24:28.539648 140498420750208 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0618 09:24:29.115423 140498420750208 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0618 09:24:29.115647 140498420750208 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0618 09:24:29.699392 140498420750208 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0618 09:24:29.699672 140498420750208 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0618 09:24:30.583144 140498420750208 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0618 09:24:30.583415 140498420750208 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0618 09:24:31.771667 140498420750208 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0618 09:24:31.771956 140498420750208 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0618 09:24:33.432138 140498420750208 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0618 09:24:33.432436 140498420750208 efficientnet_model.py:147] round_filter input=320 output=576\n",
            "I0618 09:24:34.105879 140498420750208 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
            "I0618 09:24:34.222105 140498420750208 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0618 09:24:34.374483 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0618 09:24:34.374779 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0618 09:24:34.374872 140498420750208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0618 09:24:34.377179 140498420750208 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0618 09:24:34.397805 140498420750208 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0618 09:24:34.398088 140498420750208 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0618 09:24:34.731122 140498420750208 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0618 09:24:34.731478 140498420750208 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0618 09:24:35.454609 140498420750208 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0618 09:24:35.454907 140498420750208 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0618 09:24:36.205946 140498420750208 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0618 09:24:36.206250 140498420750208 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0618 09:24:37.322181 140498420750208 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0618 09:24:37.322489 140498420750208 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0618 09:24:38.807652 140498420750208 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0618 09:24:38.807936 140498420750208 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0618 09:24:40.926131 140498420750208 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0618 09:24:40.926424 140498420750208 efficientnet_model.py:147] round_filter input=320 output=640\n",
            "I0618 09:24:42.002101 140498420750208 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
            "I0618 09:24:42.129621 140498420750208 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 34.52s\n",
            "I0618 09:24:42.309254 140498420750208 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 34.52s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0618 09:24:42.320714 140498420750208 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0618 09:24:42.323485 140498420750208 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0618 09:24:42.324406 140498420750208 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0618 09:24:42.327100 140498420750208 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0618 09:24:42.329131 140498420750208 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0618 09:24:42.329888 140498420750208 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0618 09:24:42.331260 140498420750208 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 40.182s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtWjHWsBawPq",
        "outputId": "a128f632-f48d-4e4b-f438-379b5b772a1d"
      },
      "source": [
        "%cd /content/traning_demo/pre-trained-models"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/traning_demo/pre-trained-models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyQLbGbna8_K"
      },
      "source": [
        "# !rm -r efficientdet_d0_coco17_tpu-32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTTqo5PebAZa",
        "outputId": "d67ea285-e1a9-4c37-ebc6-7232b1020d30"
      },
      "source": [
        "# https://drive.google.com/file/d/1C8J5g7zRr3rfbr9db5Q8HCOfXglOG7Kb/view?usp=sharing\n",
        "# Efficientnet pretrained model with wrinkles and darkspots\n",
        "# Comment this line if you want try with custom one\n",
        "\n",
        "!gdown --id 1C8J5g7zRr3rfbr9db5Q8HCOfXglOG7Kb\n",
        "!unzip efdnet_2C.zip\n",
        "!mv /content/traning_demo/pre-trained-models/content/traning_demo/export_model /content/traning_demo/pre-trained-models\n",
        "!mv /content/traning_demo/pre-trained-models/export_model darkspots\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# https://drive.google.com/file/d/1-0zzdLi3bGk8zlGkAyBhQQPtf_bIuMep/view?usp=sharing\n",
        "# Wrinkles\n",
        "!gdown --id 1-0zzdLi3bGk8zlGkAyBhQQPtf_bIuMep\n",
        "!unzip efdnet.zip\n",
        "!mv /content/traning_demo/pre-trained-models/content/traning_demo/export_model /content/traning_demo/pre-trained-models\n",
        "!mv /content/traning_demo/pre-trained-models/export_model Wrinkles\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# https://drive.google.com/file/d/1zvHrTZBTLJVsGixF7us2ByPmiGgb3IOj/view?usp=sharing\n",
        "# Darkspots\n",
        "!gdown --id 1zvHrTZBTLJVsGixF7us2ByPmiGgb3IOj\n",
        "!unzip darkspots.zip\n",
        "!mv /content/traning_demo/pre-trained-models/content/fine_tuned_model /content/traning_demo/pre-trained-models\n",
        "!mv /content/traning_demo/pre-trained-models/fine_tuned_model /content/traning_demo/pre-trained-models/darkspots\n",
        "\n",
        "\n",
        "# Uncomment this if you want to train from scratch\n",
        "# !wget http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n",
        "# !tar -xf /content/traning_demo/pre-trained-models/efficientdet_d0_coco17_tpu-32.tar.gz"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1C8J5g7zRr3rfbr9db5Q8HCOfXglOG7Kb\n",
            "To: /content/traning_demo/pre-trained-models/efdnet_2C.zip\n",
            "30.7MB [00:00, 74.2MB/s]\n",
            "Archive:  efdnet_2C.zip\n",
            "   creating: content/traning_demo/export_model/\n",
            "  inflating: content/traning_demo/export_model/pipeline.config  \n",
            "   creating: content/traning_demo/export_model/saved_model/\n",
            "   creating: content/traning_demo/export_model/saved_model/assets/\n",
            "  inflating: content/traning_demo/export_model/saved_model/saved_model.pb  \n",
            "   creating: content/traning_demo/export_model/saved_model/variables/\n",
            "  inflating: content/traning_demo/export_model/saved_model/variables/variables.index  \n",
            "  inflating: content/traning_demo/export_model/saved_model/variables/variables.data-00000-of-00001  \n",
            "   creating: content/traning_demo/export_model/checkpoint/\n",
            "  inflating: content/traning_demo/export_model/checkpoint/ckpt-0.index  \n",
            "  inflating: content/traning_demo/export_model/checkpoint/ckpt-0.data-00000-of-00001  \n",
            "  inflating: content/traning_demo/export_model/checkpoint/checkpoint  \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-0zzdLi3bGk8zlGkAyBhQQPtf_bIuMep\n",
            "To: /content/traning_demo/pre-trained-models/efdnet.zip\n",
            "30.7MB [00:00, 42.4MB/s]\n",
            "Archive:  efdnet.zip\n",
            "   creating: content/traning_demo/export_model/\n",
            "   creating: content/traning_demo/export_model/checkpoint/\n",
            "  inflating: content/traning_demo/export_model/checkpoint/checkpoint  \n",
            "  inflating: content/traning_demo/export_model/checkpoint/ckpt-0.index  \n",
            "  inflating: content/traning_demo/export_model/checkpoint/ckpt-0.data-00000-of-00001  \n",
            "   creating: content/traning_demo/export_model/saved_model/\n",
            "   creating: content/traning_demo/export_model/saved_model/variables/\n",
            "  inflating: content/traning_demo/export_model/saved_model/variables/variables.data-00000-of-00001  \n",
            "  inflating: content/traning_demo/export_model/saved_model/variables/variables.index  \n",
            "  inflating: content/traning_demo/export_model/saved_model/saved_model.pb  \n",
            "   creating: content/traning_demo/export_model/saved_model/assets/\n",
            "  inflating: content/traning_demo/export_model/pipeline.config  \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zvHrTZBTLJVsGixF7us2ByPmiGgb3IOj\n",
            "To: /content/traning_demo/pre-trained-models/darkspots.zip\n",
            "30.7MB [00:00, 66.0MB/s]\n",
            "Archive:  darkspots.zip\n",
            "   creating: content/fine_tuned_model/\n",
            "   creating: content/fine_tuned_model/checkpoint/\n",
            "  inflating: content/fine_tuned_model/checkpoint/checkpoint  \n",
            "  inflating: content/fine_tuned_model/checkpoint/ckpt-0.index  \n",
            "  inflating: content/fine_tuned_model/checkpoint/ckpt-0.data-00000-of-00001  \n",
            "   creating: content/fine_tuned_model/saved_model/\n",
            "   creating: content/fine_tuned_model/saved_model/variables/\n",
            "  inflating: content/fine_tuned_model/saved_model/variables/variables.data-00000-of-00001  \n",
            "  inflating: content/fine_tuned_model/saved_model/variables/variables.index  \n",
            "  inflating: content/fine_tuned_model/saved_model/saved_model.pb  \n",
            "   creating: content/fine_tuned_model/saved_model/assets/\n",
            "  inflating: content/fine_tuned_model/pipeline.config  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF50XrdcbHji",
        "outputId": "1aa6bc66-701d-42be-db4e-ce0984f96e5d"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/traning_demo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_1dXv21bPZ6",
        "outputId": "f6e95675-2082-4194-b7a9-fa70e0028cbe"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mannotations\u001b[0m/  \u001b[01;34mexport_model\u001b[0m/  \u001b[01;34mpre-trained-models\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T--FrLNbROx"
      },
      "source": [
        "# rm -r /content/traning_demo/dataset\n",
        "!rm -r /content/traning_demo/export_model/\n",
        "!mkdir export_model"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfWjABkLbS4i",
        "outputId": "d98a5ebd-3bf4-476e-c5dc-f8f258ca1c92"
      },
      "source": [
        "# https://drive.google.com/file/d/1m3gm3tKGhTQ9a_i_cLD_SS005XMX7ZM_/view?usp=sharing\n",
        "# Download the dataset\n",
        "\n",
        "!gdown --id 1m3gm3tKGhTQ9a_i_cLD_SS005XMX7ZM_\n",
        "!unzip /content/traning_demo/dataset.zip"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1m3gm3tKGhTQ9a_i_cLD_SS005XMX7ZM_\n",
            "To: /content/traning_demo/dataset.zip\n",
            "\r0.00B [00:00, ?B/s]\r5.61MB [00:00, 85.0MB/s]\n",
            "Archive:  /content/traning_demo/dataset.zip\n",
            "   creating: dataset/\n",
            "   creating: dataset/train/\n",
            "  inflating: dataset/train/AGEING SPOTS rpk (1).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (1).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (2).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (2).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (3).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (3).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (4).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (4).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (5).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (5).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (6).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (6).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (7).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (7).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (8).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (8).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (9).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (9).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (11).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (11).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (12).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (12).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (13).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (13).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (14).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (14).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (15).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (15).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (16).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (16).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (17).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (17).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (18).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (18).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (19).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (19).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (20).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (20).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (21).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (21).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (22).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (22).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (23).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (23).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (24).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (24).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (25).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (25).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (26).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (26).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (27).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (27).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (28).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (28).xml  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (32).jpeg  \n",
            "  inflating: dataset/train/AGEING SPOTS rpk (32).xml  \n",
            "  inflating: dataset/train/darkspots(24).jpg  \n",
            "  inflating: dataset/train/darkspots(24).xml  \n",
            "  inflating: dataset/train/darkspots(25).jpg  \n",
            "  inflating: dataset/train/darkspots(25).xml  \n",
            "  inflating: dataset/train/darkspots(27).jpg  \n",
            "  inflating: dataset/train/darkspots(27).xml  \n",
            "  inflating: dataset/train/darkspots(28).jpg  \n",
            "  inflating: dataset/train/darkspots(28).xml  \n",
            "  inflating: dataset/train/darkspots(30).jpg  \n",
            "  inflating: dataset/train/darkspots(30).xml  \n",
            "  inflating: dataset/train/darkspots(31).jpg  \n",
            "  inflating: dataset/train/darkspots(31).xml  \n",
            "  inflating: dataset/train/darkspots(32).jpg  \n",
            "  inflating: dataset/train/darkspots(32).xml  \n",
            "  inflating: dataset/train/darkspots(42).jpg  \n",
            "  inflating: dataset/train/darkspots(42).xml  \n",
            "  inflating: dataset/train/sunspots-freckles.jpg  \n",
            "  inflating: dataset/train/sunspots-freckles.xml  \n",
            "  inflating: dataset/train/54196f0c2590c2a308ba2233b31552bf.jpg  \n",
            "  inflating: dataset/train/54196f0c2590c2a308ba2233b31552bf.xml  \n",
            "  inflating: dataset/train/AdobeStock_94592196_Preview.jpeg  \n",
            "  inflating: dataset/train/AdobeStock_94592196_Preview.xml  \n",
            "  inflating: dataset/train/AdobeStock_413891580_Preview.jpeg  \n",
            "  inflating: dataset/train/AdobeStock_413891580_Preview.xml  \n",
            "  inflating: dataset/train/b8f3305584288da57aff6442d60efe1b(1).jpg  \n",
            "  inflating: dataset/train/b8f3305584288da57aff6442d60efe1b(1).xml  \n",
            "  inflating: dataset/train/d12b5f389eb4d6bf7ea5877341668e03.jpg  \n",
            "  inflating: dataset/train/d12b5f389eb4d6bf7ea5877341668e03.xml  \n",
            "  inflating: dataset/train/d7795e8e72ff523c161627e089a47c4a.jpg  \n",
            "  inflating: dataset/train/d7795e8e72ff523c161627e089a47c4a.xml  \n",
            "  inflating: dataset/train/d7251635fd47b820d28f0ec0cc380094.jpg  \n",
            "  inflating: dataset/train/d7251635fd47b820d28f0ec0cc380094.xml  \n",
            "  inflating: dataset/train/d8137056c6dcb47ba03c0ddd655faf4d.jpg  \n",
            "  inflating: dataset/train/d8137056c6dcb47ba03c0ddd655faf4d.xml  \n",
            "  inflating: dataset/train/df9c0185f30c288abadd03d6c913b1d1.jpg  \n",
            "  inflating: dataset/train/df9c0185f30c288abadd03d6c913b1d1.xml  \n",
            "  inflating: dataset/train/e025dfad92780bd64138da3d4a9cdede.jpg  \n",
            "  inflating: dataset/train/e025dfad92780bd64138da3d4a9cdede.xml  \n",
            "  inflating: dataset/train/e167eeeff442f4232047a184b4cb8dfe.jpg  \n",
            "  inflating: dataset/train/e167eeeff442f4232047a184b4cb8dfe.xml  \n",
            "  inflating: dataset/train/e286c2ea145b18445876f7fb53454a76.jpg  \n",
            "  inflating: dataset/train/e286c2ea145b18445876f7fb53454a76.xml  \n",
            "  inflating: dataset/train/f5a8bc08bd6c2c177e868f11e75e0e1c.jpg  \n",
            "  inflating: dataset/train/f5a8bc08bd6c2c177e868f11e75e0e1c.xml  \n",
            "  inflating: dataset/train/f00192e229e154155142c8e71f453006.jpg  \n",
            "  inflating: dataset/train/f00192e229e154155142c8e71f453006.xml  \n",
            "  inflating: dataset/train/face-505392_1920.jpg  \n",
            "  inflating: dataset/train/face-505392_1920.xml  \n",
            "  inflating: dataset/train/face-3760920_1920.jpg  \n",
            "  inflating: dataset/train/face-3760920_1920.xml  \n",
            "  inflating: dataset/train/fisherman-4473635_1920.jpg  \n",
            "  inflating: dataset/train/fisherman-4473635_1920.xml  \n",
            "  inflating: dataset/train/images.jpeg  \n",
            "  inflating: dataset/train/images.xml  \n",
            "  inflating: dataset/train/images (1).jpeg  \n",
            "  inflating: dataset/train/images (1).xml  \n",
            "  inflating: dataset/train/images (2).jpeg  \n",
            "  inflating: dataset/train/images (2).xml  \n",
            "  inflating: dataset/train/images (3).jpeg  \n",
            "  inflating: dataset/train/images (3).xml  \n",
            "   creating: dataset/test/\n",
            "  inflating: dataset/test/darkspots(34).jpg  \n",
            "  inflating: dataset/test/darkspots(34).xml  \n",
            "  inflating: dataset/test/darkspots(35).jpg  \n",
            "  inflating: dataset/test/darkspots(35).xml  \n",
            "  inflating: dataset/test/darkspots(36).jpg  \n",
            "  inflating: dataset/test/darkspots(36).xml  \n",
            "  inflating: dataset/test/darkspots(38).jpg  \n",
            "  inflating: dataset/test/darkspots(38).xml  \n",
            "  inflating: dataset/test/darkspots(41).jpg  \n",
            "  inflating: dataset/test/darkspots(41).xml  \n",
            "  inflating: dataset/test/2e9d2cf00cd6914858d09eca89123db4.png  \n",
            "  inflating: dataset/test/2e9d2cf00cd6914858d09eca89123db4.xml  \n",
            "  inflating: dataset/test/5f4278a310117792c164ed4d3e20f586.jpg  \n",
            "  inflating: dataset/test/5f4278a310117792c164ed4d3e20f586.xml  \n",
            "  inflating: dataset/test/8a001b598654b4cfda459e942de88732.jpg  \n",
            "  inflating: dataset/test/8a001b598654b4cfda459e942de88732.xml  \n",
            "  inflating: dataset/test/8af314f7da8f1782e4d932effe015967.jpg  \n",
            "  inflating: dataset/test/8af314f7da8f1782e4d932effe015967.xml  \n",
            "  inflating: dataset/test/8d61ebfd5bced16340ce67e2c8152f55.jpg  \n",
            "  inflating: dataset/test/8d61ebfd5bced16340ce67e2c8152f55.xml  \n",
            "  inflating: dataset/test/0101a9d44ee8b2ef49d3ab634b1f1e9a.jpg  \n",
            "  inflating: dataset/test/0101a9d44ee8b2ef49d3ab634b1f1e9a.xml  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PP5oUOVbbX1C",
        "outputId": "fca476a8-0795-4b63-cbc4-aef0c912df84"
      },
      "source": [
        "# https://drive.google.com/file/d/1C1vNYIgXbxhN1p4NgpKX_BU15DHGOQyw/view?usp=sharing\n",
        "# Download required python files\n",
        "!gdown --id 1C1vNYIgXbxhN1p4NgpKX_BU15DHGOQyw\n",
        "!unzip python_files.zip\n",
        "!mv label_map.pbtxt /content/traning_demo/annotations"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1C1vNYIgXbxhN1p4NgpKX_BU15DHGOQyw\n",
            "To: /content/traning_demo/python_files.zip\n",
            "\r  0% 0.00/6.93k [00:00<?, ?B/s]\r100% 6.93k/6.93k [00:00<00:00, 15.5MB/s]\n",
            "Archive:  python_files.zip\n",
            "  inflating: exporter_main_v2.py     \n",
            "  inflating: generate_tfrecord.py    \n",
            "  inflating: label_map.pbtxt         \n",
            "  inflating: model_main_tf2.py       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ve7bA3ufbZnK",
        "outputId": "d3e8d8f5-726a-4477-da3a-3e3bb108662a"
      },
      "source": [
        "# Create train data:\n",
        "!python /content/traning_demo/generate_tfrecord.py -x /content/traning_demo/dataset/train -l /content/traning_demo/annotations/label_map.pbtxt -o /content/traning_demo/annotations/train.record\n",
        "\n",
        "# Create test data:\n",
        "!python /content/traning_demo/generate_tfrecord.py -x /content/traning_demo/dataset/test -l /content/traning_demo/annotations/label_map.pbtxt -o/content/traning_demo/annotations/test.record"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully created the TFRecord file: /content/traning_demo/annotations/train.record\n",
            "Successfully created the TFRecord file: /content/traning_demo/annotations/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgvW8QV_bb2a",
        "outputId": "85f502a6-2782-465b-d2be-42c357312e3f"
      },
      "source": [
        "!mkdir my_model"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘my_model’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq2cJon1bzcK"
      },
      "source": [
        "# !cp /content/traning_demo/pre-trained-models/efficientdet_d0_coco17_tpu-32/pipeline.config /content/traning_demo/my_model"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF0K9KEUb74Z",
        "outputId": "be71f172-07fc-43e7-9a18-5f1d0026c0c2"
      },
      "source": [
        "%cd /content/traning_demo"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/traning_demo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LPO-gqcvb_B4",
        "outputId": "ffcabe87-3ddf-47cb-ce23-2e253ad6b2ec"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/traning_demo'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwzwnvZFcAzZ"
      },
      "source": [
        "!rm -r /content/traning_demo/export_model\n",
        "!mkdir export_model"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7uj5OXlcHQx",
        "outputId": "ae5028f9-fcac-4d1a-938b-957f8ac66b53"
      },
      "source": [
        "#Train \n",
        "#%%time\n",
        "!python /content/traning_demo/model_main_tf2.py --model_dir=/content/traning_demo/my_model --pipeline_config_path=/content/traning_demo/my_model/pipeline.config"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-18 09:29:41.184018: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-06-18 09:29:44.350118: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-06-18 09:29:44.362623: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-06-18 09:29:44.362703: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (d197517b1c6a): /proc/driver/nvidia/version does not exist\n",
            "2021-06-18 09:29:44.363281: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "W0618 09:29:44.364667 140479780870016 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "W0618 09:29:44.365075 140479780870016 mirrored_strategy.py:379] Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "I0618 09:29:44.368651 140479780870016 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/traning_demo/model_main_tf2.py\", line 113, in <module>\n",
            "    tf.compat.v1.app.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 303, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 251, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/traning_demo/model_main_tf2.py\", line 110, in main\n",
            "    record_summaries=FLAGS.record_summaries)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 499, in train_loop\n",
            "    pipeline_config_path, config_override=config_override)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/utils/config_util.py\", line 138, in get_configs_from_pipeline_file\n",
            "    proto_str = f.read()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/lib/io/file_io.py\", line 117, in read\n",
            "    self._preread_check()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/lib/io/file_io.py\", line 80, in _preread_check\n",
            "    compat.path_to_str(self.__name), 1024 * 512)\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: /content/traning_demo/my_model/pipeline.config; No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Flboc-g1cKih"
      },
      "source": [
        "# Exporting model\n",
        "# %%time\n",
        "#!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path /content/traning_demo/my_model/pipeline.config --trained_checkpoint_dir /content/traning_demo/my_model --output_directory=/content/traning_demo/export_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZvcINmZcTiJ"
      },
      "source": [
        "#!cp -r /content/traning_demo/pre-trained-models/efficientdet_d0_coco17_tpu-32/. /content/traning_demo/export_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOCzbL7TcXGK",
        "outputId": "da77e222-6ddd-4cc2-c2f0-897e397076b4"
      },
      "source": [
        "%%time\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import argparse\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import time\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "\n",
        "\n",
        "# PROVIDE PATH TO MODEL DIRECTORY\n",
        "PATH_TO_MODEL_DIR_WRINKLES = '/content/traning_demo/pre-trained-models/Wrinkles'\n",
        "\n",
        "MIN_CONF_THRESH = float(0.10)\n",
        "\n",
        "# LOAD THE MODEL\n",
        "\n",
        "PATH_TO_SAVED_MODEL_WRINKLES = PATH_TO_MODEL_DIR_WRINKLES + \"/saved_model\"\n",
        "\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
        "detect_fn_wrinkles = tf.saved_model.load(PATH_TO_SAVED_MODEL_WRINKLES)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model..."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_99813) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_96205) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_90200) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_call_func_18512) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_86592) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_64447) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_62827) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_call_func_80845) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done! Took 33.730364084243774 seconds\n",
            "CPU times: user 31 s, sys: 3.13 s, total: 34.1 s\n",
            "Wall time: 33.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mDPtGiAccih",
        "outputId": "f17457cc-a2bb-414c-ac5a-56321df54040"
      },
      "source": [
        "PATH_TO_MODEL_DIR_DARKSPOTS = '/content/traning_demo/pre-trained-models/darkspots'\n",
        "\n",
        "MIN_CONF_THRESH = float(0.10)\n",
        "\n",
        "# LOAD THE MODEL\n",
        "\n",
        "PATH_TO_SAVED_MODEL_DARKSPOTS = PATH_TO_MODEL_DIR_DARKSPOTS + \"/saved_model\"\n",
        "\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
        "detect_fn_darkspots = tf.saved_model.load(PATH_TO_SAVED_MODEL_DARKSPOTS)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model..."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_119573) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_88634) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_60359) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_55794) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_95985) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_121193) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_84891) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_call_func_18624) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_EfficientDet-D0_layer_call_and_return_conditional_losses_92242) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_call_func_79375) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done! Took 34.8440203666687 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1lnBuQOcqZx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "2a40cdbf-0011-4ef7-e6a4-30db370722eb"
      },
      "source": [
        "#  import numpy as np\n",
        "#  from PIL import Image\n",
        "#  import matplotlib.pyplot as plt\n",
        "#  import warnings\n",
        "#  import cv2\n",
        "#  warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "#   #PROVIDE PATH TO IMAGE DIRECTORY\n",
        "#  IMAGE_PATHS = '/content/traning_demo/dataset/test/5f4278a310117792c164ed4d3e20f586.jpg'\n",
        "\n",
        "#   #PROVIDE PATH TO LABEL MAP\n",
        "#  PATH_TO_LABELS = '/content/traning_demo/annotations/label_map.pbtxt'\n",
        "\n",
        "#  #LOAD LABEL MAP DATA FOR PLOTTING\n",
        "\n",
        "#  category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
        "#                                                                      use_display_name=True)\n",
        "\n",
        "\n",
        "#  print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n",
        "\n",
        "#  image = cv2.imread(IMAGE_PATHS)\n",
        "#  image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "#  image_expanded = np.expand_dims(image_rgb, axis=0)\n",
        "\n",
        "\n",
        "#  input_tensor = tf.convert_to_tensor(image)\n",
        "\n",
        "#  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "\n",
        "# detections = detect_fn(input_tensor)\n",
        "\n",
        "#  num_detections = int(detections.pop('num_detections'))\n",
        "#  detections = {key: value[0, :num_detections].numpy()\n",
        "#                 for key, value in detections.items()}\n",
        "#  detections['num_detections'] = num_detections\n",
        "\n",
        "#  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "#  image_with_detections = image.copy()\n",
        "\n",
        "#  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "#        image_with_detections,\n",
        "#        detections['detection_boxes'],\n",
        "#        detections['detection_classes'],\n",
        "#        detections['detection_scores'],\n",
        "#        category_index,\n",
        "#        use_normalized_coordinates=True,\n",
        "#        max_boxes_to_draw=200,\n",
        "#        min_score_thresh=0.4,\n",
        "#        agnostic_mode=False)\n",
        "\n",
        "# print('Done')\n",
        "# #DISPLAYS OUTPUT IMAGE\n",
        "# cv2_imshow(image_with_detections)\n",
        "# cv2.imwrite(\"Test.jpg\", image_with_detections)\n",
        "# #CLOSES WINDOW ONCE KEY IS PRESSED"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running inference for /content/traning_demo/dataset/test/5f4278a310117792c164ed4d3e20f586.jpg... "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-8060fac78d95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mnum_detections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num_detections'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'detect_fn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iULHg5yldDtq",
        "outputId": "babcfcb7-0b39-423a-c099-476ef58262f6"
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.25.1)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.5.30)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g9-gOkafhjh",
        "outputId": "28d09ca1-1af4-4c7e-e18b-164aa671aad8"
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "J-pJ_aPqfjaY",
        "outputId": "70bcb01c-1ce9-4f96-c3fa-0d57e63ae560"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8Z9z1izfk64",
        "outputId": "4267a937-29a8-447b-d22c-05535f7a69d4"
      },
      "source": [
        "# https://drive.google.com/file/d/1iWvskjmJD4Xr1x2NtV0TYJm116lh1MHq/view?usp=sharing\n",
        "!gdown --id 1iWvskjmJD4Xr1x2NtV0TYJm116lh1MHq\n",
        "!unzip webpage.zip"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1iWvskjmJD4Xr1x2NtV0TYJm116lh1MHq\n",
            "To: /content/webpage.zip\n",
            "7.40MB [00:00, 34.2MB/s]\n",
            "Archive:  webpage.zip\n",
            "   creating: static/\n",
            "   creating: static/uploads/\n",
            "   creating: static/css/\n",
            "  inflating: static/css/banner1.jpg  \n",
            "  inflating: static/css/style.css    \n",
            "  inflating: static/css/banner3.jpg  \n",
            "  inflating: static/css/img2.jpg     \n",
            "   creating: templates/\n",
            "  inflating: templates/index.html    \n",
            "  inflating: templates/result.html   \n",
            "  inflating: haarcascade_eye.xml     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeSEdA7bfmdp",
        "outputId": "31f71901-7574-4fea-c251-80e9ef280eba"
      },
      "source": [
        "# https://drive.google.com/file/d/1fMsK5T1S0rkzzth5wVcMHDbY4H5gYZTA/view?usp=sharing\n",
        "# Efficientnet model. For pluffy eyes\n",
        "!gdown --id 1fMsK5T1S0rkzzth5wVcMHDbY4H5gYZTA"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fMsK5T1S0rkzzth5wVcMHDbY4H5gYZTA\n",
            "To: /content/efficientnet.h5\n",
            "16.7MB [00:00, 102MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxAopSzAfp8w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37a01aa3-0458-4ab0-cb43-c09099a60171"
      },
      "source": [
        "# https://drive.google.com/file/d/1OzT-szWYdMFQIVX-KQ7PMLhjuSdgAf7Z/view?usp=sharing\n",
        "!gdown --id 1OzT-szWYdMFQIVX-KQ7PMLhjuSdgAf7Z"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OzT-szWYdMFQIVX-KQ7PMLhjuSdgAf7Z\n",
            "To: /content/shape_predictor_81_face_landmarks.dat\n",
            "19.7MB [00:00, 74.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWFUhdB5fsDI"
      },
      "source": [
        "import os\n",
        "import urllib.request\n",
        "from flask import Flask, flash, request, redirect, url_for, render_template\n",
        "from werkzeug.utils import secure_filename\n",
        "\n",
        "\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "\n",
        "\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import dlib\n",
        "import glob\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG5bbP61fuUQ"
      },
      "source": [
        "predictor_path = 'shape_predictor_81_face_landmarks.dat'\n",
        "\n",
        "\n",
        "def face_extract(path):\n",
        "\n",
        "    img=cv2.imread(path)\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    hog_face_detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "    detector = dlib.get_frontal_face_detector()\n",
        "    predictor = dlib.shape_predictor(predictor_path)\n",
        "\n",
        "    dets = detector(img, 0)\n",
        "\n",
        "    facePoints = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 78, 74, 79, 73, 72, 80, 71, 70, 69, 68, 76, 75, 77, 0]\n",
        "\n",
        "    for k, d in enumerate(dets):\n",
        "        shape = predictor(img, d)\n",
        "        landmarks = np.matrix([[p.x, p.y] for p in shape.parts()])\n",
        "\n",
        "        mask = np.zeros(img.shape[:2], np.uint8)\n",
        "\n",
        "        face = np.array([ [shape.parts()[num].x, shape.parts()[num].y] for num in facePoints ])\n",
        "\n",
        "        cv2.drawContours(mask, [np.array(face)], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
        "\n",
        "        dst = cv2.bitwise_and(img, img, mask=mask)\n",
        "\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.imshow(dst)\n",
        "        return dst, img"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnt7bP9df2KI"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import cv2\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "def effecientDet_wrinkles(path):\n",
        "\n",
        "  # IMAGE_PATHS = path\n",
        "\n",
        "  PATH_TO_LABELS = '/content/traning_demo/annotations/label_map.pbtxt'\n",
        "\n",
        "  category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
        "\n",
        "\n",
        "  print('Running inference... ', end='')\n",
        "\n",
        "  # image = cv2.imread(IMAGE_PATHS)\n",
        "  image = path\n",
        "  image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  image_expanded = np.expand_dims(image_rgb, axis=0)\n",
        "\n",
        "\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "\n",
        "  detections = detect_fn_wrinkles(input_tensor)\n",
        "\n",
        "  num_detections = int(detections.pop('num_detections'))\n",
        "  detections = {key: value[0, :num_detections].numpy()\n",
        "                for key, value in detections.items()}\n",
        "  detections['num_detections'] = num_detections\n",
        "\n",
        "  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "  image_with_detections = image.copy()\n",
        "\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_with_detections,\n",
        "        detections['detection_boxes'],\n",
        "        detections['detection_classes'],\n",
        "        detections['detection_scores'],\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=200,\n",
        "        min_score_thresh=0.4,\n",
        "        agnostic_mode=False)\n",
        "\n",
        "  return image_with_detections\n",
        "\n",
        "def effecientDet_darkspots(path):\n",
        "\n",
        "  # IMAGE_PATHS = path\n",
        "\n",
        "  PATH_TO_LABELS = '/content/traning_demo/annotations/label_map.pbtxt'\n",
        "\n",
        "  category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
        "\n",
        "\n",
        "  print('Running inference... ', end='')\n",
        "\n",
        "  # image = cv2.imread(IMAGE_PATHS)\n",
        "  image = path\n",
        "  image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  image_expanded = np.expand_dims(image_rgb, axis=0)\n",
        "\n",
        "\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "\n",
        "  detections = detect_fn_darkspots(input_tensor)\n",
        "\n",
        "  num_detections = int(detections.pop('num_detections'))\n",
        "  detections = {key: value[0, :num_detections].numpy()\n",
        "                for key, value in detections.items()}\n",
        "  detections['num_detections'] = num_detections\n",
        "\n",
        "  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "  image_with_detections = image.copy()\n",
        "\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_with_detections,\n",
        "        detections['detection_boxes'],\n",
        "        detections['detection_classes'],\n",
        "        detections['detection_scores'],\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=200,\n",
        "        min_score_thresh=0.4,\n",
        "        agnostic_mode=False)\n",
        "\n",
        "  return image_with_detections"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBRm16-Lf9o5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "044bada6-e7a0-4b82-e943-31c1eabf5f32"
      },
      "source": [
        "#  file_path = '/content/54196f0c2590c2a308ba2233b31552bf.jpg'\n",
        "#  img, orgImg = face_extract(file_path)\n",
        "#  plt.imshow(img)\n",
        "#  plt.show()\n",
        "\n",
        "\n",
        "#  img = effecientDet_wrinkles(img)\n",
        "#  cv2_imshow(img)\n",
        "#  img = effecientDet_darkspots(img)\n",
        "#  cv2_imshow(img)\n",
        "\n",
        "#  left_eye, right_eye, eye_points, img = eyes(img)\n",
        "#  img, percent = predict_puffyeyes(left_eye, right_eye, eye_points, img, orgImg)\n",
        "#  plt.imshow(img)\n",
        "#  plt.show()\n",
        "#  cv2.imwrite(file_path, img)\n",
        "# print(percent)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-74115cd388fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/54196f0c2590c2a308ba2233b31552bf.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morgImg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-5971767df1ee>\u001b[0m in \u001b[0;36mface_extract\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mhog_face_detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.5.2) /tmp/pip-req-build-gvmai4nm/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U39ClOmFgLnQ"
      },
      "source": [
        "model=load_model('efficientnet.h5')\n",
        "eye_cascade=cv2.CascadeClassifier('haarcascade_eye.xml')\n",
        "\n",
        "def eyes(path):\n",
        "\timg=cv2.imread(path)\n",
        "\timg = path.copy()\n",
        "\teye_rects=eye_cascade.detectMultiScale(img)\n",
        "\teye_points=[]\n",
        "\tfor x,y,w,h in eye_rects:\n",
        "\t\teye_points.append([x,y,w,h])\n",
        "\tx1=eye_points[0][0]\n",
        "\ty1=eye_points[0][1]\n",
        "\tx2=eye_points[0][0]+eye_points[0][2]\n",
        "\ty2=eye_points[0][1]+eye_points[0][3]+30\n",
        "\tleft_eye=img[y1:y2,x1:x2]\n",
        "\tleft_eye=Image.fromarray(left_eye)\n",
        "\tleft_eye=left_eye.resize((224,224))\n",
        "\tleft_eye=asarray(left_eye)\n",
        "\tif len(eye_points)>1:\n",
        "\t\tx1=eye_points[1][0]\n",
        "\t\ty1=eye_points[1][1]\n",
        "\t\tx2=eye_points[1][0]+eye_points[1][2]  \n",
        "\t\ty2=eye_points[1][1]+eye_points[1][3]+30\n",
        "\t\tright_eye=img[y1:y2,x1:x2]\n",
        "\t\tright_eye=Image.fromarray(right_eye)\n",
        "\t\tright_eye=right_eye.resize((224,224))\n",
        "\t\tright_eye=asarray(right_eye)\n",
        "\telse:\n",
        "\t\tright_eye=0\n",
        "\treturn left_eye, right_eye, eye_points, img\n",
        "\n",
        "def predict_puffyeyes(left_eye,right_eye,l1,img, orgImg):\n",
        "\ttest_image=np.expand_dims(left_eye,axis=0)\n",
        "\tresult=model.predict(test_image)\n",
        "\ttempImg = orgImg.copy()\n",
        "\tif result[0][0]>result[0][1]:\n",
        "\t\treturn orgImg, \"No puffy eyes present\"\n",
        "\telse:\n",
        "\t\tprint('left puffy eyes percentage',result[0][1]*100,'%')\n",
        "\t\tb=round(result[0][1]*100,2)\n",
        "\t\tx,y,w,h=l1[0]\n",
        "\t\tcv2.rectangle(tempImg, (x,y), (x+w,y+h+30), (0,255,255), 2)\n",
        "\t\tcv2.putText(tempImg,'Puffy eyes',(x,y+h+15), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,0,25), 1, cv2.LINE_AA)\n",
        "\tif type(right_eye)!=int:\n",
        "\t\ttest_image=np.expand_dims(right_eye,axis=0)\n",
        "\t\tresult=model.predict(test_image)\n",
        "\t\tif result[0][0]>result[0][1]:\n",
        "\t\t\treturn orgImg, \"No puffy eyes present\"\n",
        "\t\telse:\n",
        "\t\t\tprint('right puffy eyes percentage',result[0][1]*100,'%')\n",
        "\t\t\ta=round(result[0][1]*100,1)\n",
        "\t\t\tx,y,w,h=l1[1]\n",
        "\t\t\tcv2.rectangle(tempImg, (x,y), (x+w,y+h+30), (0,255,255), 2)\n",
        "\t\t\tcv2.putText(tempImg,'Puffy eyes',(x,y+h+15), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,0,25), 1, cv2.LINE_AA)\n",
        "\t\t\treturn tempImg, \"\"\n",
        "\treturn orgImg, \"\""
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB5jyR6wgPqw"
      },
      "source": [
        "# img, orgImg = face_extract('/content/traning_demo/dataset/test/darkspots(41).jpg')\n",
        "# left_eye, right_eye, eye_points, img = eyes(img)\n",
        "# img, percent = predict_puffyeyes(left_eye, right_eye, eye_points, img, orgImg)\n",
        "# img = effecientDet(img)\n",
        "# print(percent)\n",
        "# plt.imshow(img)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz_ifJm_gTBA"
      },
      "source": [
        "def load_img(path) :\n",
        "  img=cv2.imread(path)\n",
        "  return img"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CJE1BW9gskq",
        "outputId": "7691c5be-f53c-476f-a45f-c8e3fd43c7c4"
      },
      "source": [
        "UPLOAD_FOLDER = 'static/uploads/'\n",
        "\n",
        "app = Flask(__name__, template_folder='templates')\n",
        "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
        "\n",
        "run_with_ngrok(app)\n",
        "\n",
        "ALLOWED_EXTENSIONS = set(['png', 'jpg', 'jpeg', 'gif'])\n",
        "\n",
        "def allowed_file(filename):\n",
        "\treturn '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
        "\t\n",
        "@app.route('/')\n",
        "def upload_form():\n",
        "\treturn render_template('index.html')\n",
        "\n",
        "@app.route('/', methods=['POST'])\n",
        "def upload_image():\n",
        "\tprint(\"File uploaded\")\n",
        "\tif 'file' not in request.files:\n",
        "\t\treturn redirect(request.url)\n",
        "\tfile = request.files['file']\n",
        "\tif file.filename == '':\n",
        "\t\tflash('No image selected for uploading')\n",
        "\t\treturn redirect(request.url)\n",
        "\tif file and allowed_file(file.filename):\n",
        "\t\tfilename = secure_filename(file.filename)\n",
        "\t\t\n",
        "\n",
        "\t\tfile_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
        "\t\tfile.save(file_path)\n",
        "\t\tprint('upload_image filename: ' + filename)\n",
        "\t\tprint(file_path)\n",
        "\t\tpercent = \"\"\n",
        "\t\ttry:\n",
        "\t\t\t\t# img, orgImg = face_extract(file_path)\n",
        "\t\t\t\timg = load_img(file_path)\n",
        "\t\t\t\torgImg = img\n",
        "\n",
        "\t\t\t\timg = effecientDet_wrinkles(img)\n",
        "\t\t\t\t# cv2_imshow(img)\n",
        "\t\t\t\timg = effecientDet_darkspots(img)\n",
        "\t\t\t\t# cv2_imshow(img)\n",
        "\t\t\t\torgImg = img.copy()\n",
        "\t\t\t\tleft_eye, right_eye, eye_points, img = eyes(img)    \n",
        "\t\t\t\timg, percent = predict_puffyeyes(left_eye, right_eye, eye_points, img, img)\n",
        "\t\t\t\t# cv2_imshow(img)\n",
        "\n",
        "\t\t\t\tcv2.imwrite(file_path, img)\n",
        "\t\t\t\tprint(percent)\n",
        "\n",
        "\t\t\t\treturn render_template('result.html', filename=filename, eyes=percent)\n",
        "\t\texcept :\n",
        "\t\t\t\tprint(\"exception in eyes\")\n",
        "\t\t\t\tcv2.imwrite(file_path, img)\n",
        "\t\t\t\treturn render_template('result.html', filename=filename, eyes=\"No puffy eyes present\")\n",
        "\telse:\n",
        "\t\t# flash('Allowed image types are -> png, jpg, jpeg, gif')\n",
        "\t\treturn redirect(request.url)\n",
        "\n",
        "@app.route('/display/<filename>')\n",
        "def display_image(filename):\n",
        "\tprint('display_image filename: ' + filename)\n",
        "\treturn redirect(url_for('static', filename='uploads/' + filename), code=301)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\tapp.run()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://57a9f1120234.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:12:59] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:13:08] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:13:08] \"\u001b[37mGET /static/css/style.css HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:13:08] \"\u001b[37mGET /static/css/img2.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:13:08] \"\u001b[37mGET /static/css/banner1.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:13:09] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:13:09] \"\u001b[37mGET /static/css/banner3.jpg HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "File uploaded\n",
            "upload_image filename: 1_1.png\n",
            "static/uploads/1_1.png\n",
            "Running inference... Running inference... "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:14:01] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "exception in eyes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:14:02] \"\u001b[32mGET /display/1_1.png HTTP/1.1\u001b[0m\" 301 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "display_image filename: 1_1.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:14:03] \"\u001b[37mGET /static/uploads/1_1.png HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:16:47] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "File uploaded\n",
            "upload_image filename: 1_1.png\n",
            "static/uploads/1_1.png\n",
            "Running inference... Running inference... "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:16:50] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "exception in eyes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:18:12] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:18:15] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "File uploaded\n",
            "upload_image filename: 50000464ccf7dd4d8b562c5add10ad10.jpg\n",
            "static/uploads/50000464ccf7dd4d8b562c5add10ad10.jpg\n",
            "Running inference... Running inference... "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:18:23] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "exception in eyes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:18:24] \"\u001b[32mGET /display/50000464ccf7dd4d8b562c5add10ad10.jpg HTTP/1.1\u001b[0m\" 301 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "display_image filename: 50000464ccf7dd4d8b562c5add10ad10.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:18:24] \"\u001b[37mGET /static/uploads/50000464ccf7dd4d8b562c5add10ad10.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:18:37] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "File uploaded\n",
            "upload_image filename: Image_10.jpg\n",
            "static/uploads/Image_10.jpg\n",
            "Running inference... Running inference... "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:19:00] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "exception in eyes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:19:00] \"\u001b[32mGET /display/Image_10.jpg HTTP/1.1\u001b[0m\" 301 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "display_image filename: Image_10.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:19:00] \"\u001b[37mGET /static/uploads/Image_10.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:19:13] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "File uploaded\n",
            "upload_image filename: Image_13.jpg\n",
            "static/uploads/Image_13.jpg\n",
            "Running inference... Running inference... "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:19:20] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "exception in eyes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:19:20] \"\u001b[32mGET /display/Image_13.jpg HTTP/1.1\u001b[0m\" 301 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "display_image filename: Image_13.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:19:21] \"\u001b[37mGET /static/uploads/Image_13.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:19:31] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "File uploaded\n",
            "upload_image filename: Image_44.jpg\n",
            "static/uploads/Image_44.jpg\n",
            "Running inference... Running inference... "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:19:41] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "exception in eyes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:19:41] \"\u001b[32mGET /display/Image_44.jpg HTTP/1.1\u001b[0m\" 301 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "display_image filename: Image_44.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:19:41] \"\u001b[37mGET /static/uploads/Image_44.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:30:42] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:30:43] \"\u001b[37mGET /static/css/style.css HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:30:43] \"\u001b[37mGET /static/css/banner3.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:30:43] \"\u001b[37mGET /static/css/img2.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:30:43] \"\u001b[37mGET /static/css/banner1.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2021 10:30:44] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3c5GvmZgvYg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}